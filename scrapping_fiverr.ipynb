{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate\n",
    "s=Service('C:/SAINS DATA/chromedriver.exe')\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "options.add_argument('disable_infobars')\n",
    "# options.headless = True\n",
    "\n",
    "driver = webdriver.Chrome(service=s, options=options)\n",
    "url=\"https://www.fiverr.com/search/gigs?query=web%20scraping&source=top-bar&acmpl=1&search_in=everywhere&search-autocomplete-original-term=web%20scrapping&search-autocomplete-available=true&search-autocomplete-type=suggest&search-autocomplete-position=2\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.common.action_chains.ActionChains at 0x13af4fcc4f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element = driver.find_element(By.CSS_SELECTOR, '#px-captcha')\n",
    "action = ActionChains(driver)\n",
    "click = ActionChains(driver)\n",
    "action.click_and_hold(element)\n",
    "action.perform()\n",
    "time.sleep(10)\n",
    "action.release(element)\n",
    "action.perform()\n",
    "time.sleep(0.2)\n",
    "action.release(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I will do data entry,data mining,web scraping and data extraction', 'I will do web scraping, data mining any website upto 50k in 1 day', 'I will do web scraping, website scraping, web scraper in python', 'I will do email collection, data collection,data mining,linkedin scraping, web scraping', 'I will be your python web scraping or crawling developer', 'I will do web scraping, data mining in 5 hours', 'I will do web scraping, crawling and data mining with python and nodejs', 'I will do web scraping, data scraping and data extraction', 'I will do web scraping, data extraction or build custom web scraper', 'I will do python web scraping and data mining', 'I will scrape any data you want from the world wide web', 'I will be your virtual assistant for data entry web research and data scraping', 'I will do web scraping data mining data extraction', 'I will accurately do data mining, data collection, web scraping', 'I will do web scraping or data scraping from almost any website', 'I will conduct web scraping using python', 'I will do python web scraping , data entry , and data extraction', 'I will do web scraping or data mining from almost any website', 'I will do data mining, web scraping, data extraction,excel CSV job', 'I will build python web scraper automation tool for web scraping data extraction', 'I will do web scraping from any website you wish', 'I will do python web scraping, data mining, data scraping, web scraper', 'I will do web scraping and data processing from almost any web site', 'I will create a fast web scraping program in python', 'I will do data mining, web scraping, and extraction', 'I will do excel data entry expert, web scraping, virtual assistant,lead generation', 'I will data mining, web scraping, data processing, aggregate data', 'I will data collect niche targeted email list web scraping, mining and research', 'I will do python web scraping data mining from any website', 'I will be virtual assistant for data entry, data mining, web research, scraping, typing', 'I will do python web scraping, data mining, web scraper, data scraper', 'I will automate data mining and web scraping', 'I will do perfect web scraping, data mining for you using python', 'I will do web scraping with octoparse in 24hrs', 'I will do any web scraping, web scraper, yellow page scraping, amazon scraping', 'I will do data entry, copy paste, web research, web scraping and excel data entry', 'I will do python web scraping and automation', 'I will do python scripts, web scraping, PDF extraction and automation', 'I will do web scraping, data mining, and data extraction', 'I will do data entry, data mining, web scraping and copy paste', 'I will do python web scraping or data mining of any website', 'I will do web research, email finding, data entry, web scraping', 'I will do product scraping, web scraping, image scraping', 'I will do web scraping, web crawling, data scraping using ubot', 'I will do web scraping and data extraction for your project', 'I will do data entry,data mining,web scraping and data extraction', 'I will do web scraping, web scraper, web data scraper, website scraping', 'I will do web scraping, data mining, data extraction on any website', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "offer = driver.find_elements(By.TAG_NAME, 'h3')\n",
    "print([i.text for i in offer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will do data entry,data mining,web scraping and data extraction\n",
      "I will do web scraping, data mining any website upto 50k in 1 day\n",
      "I will do web scraping, website scraping, web scraper in python\n",
      "I will do email collection, data collection,data mining,linkedin scraping, web scraping\n",
      "I will be your python web scraping or crawling developer\n",
      "I will do web scraping, data mining in 5 hours\n",
      "I will do web scraping, crawling and data mining with python and nodejs\n",
      "I will do web scraping, data scraping and data extraction\n",
      "I will do web scraping, data extraction or build custom web scraper\n",
      "I will do python web scraping and data mining\n",
      "I will scrape any data you want from the world wide web\n",
      "I will be your virtual assistant for data entry web research and data scraping\n",
      "I will do web scraping data mining data extraction\n",
      "I will accurately do data mining, data collection, web scraping\n",
      "I will do web scraping or data scraping from almost any website\n",
      "I will conduct web scraping using python\n",
      "I will do python web scraping , data entry , and data extraction\n",
      "I will do web scraping or data mining from almost any website\n",
      "I will do data mining, web scraping, data extraction,excel CSV job\n",
      "I will build python web scraper automation tool for web scraping data extraction\n",
      "I will do web scraping from any website you wish\n",
      "I will do python web scraping, data mining, data scraping, web scraper\n",
      "I will do web scraping and data processing from almost any web site\n",
      "I will create a fast web scraping program in python\n",
      "I will do data mining, web scraping, and extraction\n",
      "I will do excel data entry expert, web scraping, virtual assistant,lead generation\n",
      "I will data mining, web scraping, data processing, aggregate data\n",
      "I will data collect niche targeted email list web scraping, mining and research\n",
      "I will do python web scraping data mining from any website\n",
      "I will be virtual assistant for data entry, data mining, web research, scraping, typing\n",
      "I will do python web scraping, data mining, web scraper, data scraper\n",
      "I will automate data mining and web scraping\n",
      "I will do perfect web scraping, data mining for you using python\n",
      "I will do web scraping with octoparse in 24hrs\n",
      "I will do any web scraping, web scraper, yellow page scraping, amazon scraping\n",
      "I will do data entry, copy paste, web research, web scraping and excel data entry\n",
      "I will do python web scraping and automation\n",
      "I will do python scripts, web scraping, PDF extraction and automation\n",
      "I will do web scraping, data mining, and data extraction\n",
      "I will do data entry, data mining, web scraping and copy paste\n",
      "I will do python web scraping or data mining of any website\n",
      "I will do web research, email finding, data entry, web scraping\n",
      "I will do product scraping, web scraping, image scraping\n",
      "I will do web scraping, web crawling, data scraping using ubot\n",
      "I will do web scraping and data extraction for your project\n",
      "I will do data entry,data mining,web scraping and data extraction\n",
      "I will do web scraping, web scraper, web data scraper, website scraping\n",
      "I will do web scraping, data mining, data extraction on any website\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "gig_layout = driver.find_elements(By.CLASS_NAME, 'gig-card-layout')\n",
    "for i in gig_layout: \n",
    "    gig_title = i.find_element(By.TAG_NAME, 'h3')\n",
    "    print(gig_title.text)\n",
    "    \n",
    "print(len(gig_layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STARTING AT$40', 'STARTING AT$10', 'STARTING AT$75', 'STARTING AT$5', 'STARTING AT$200', 'STARTING AT$25', 'STARTING AT$80', 'STARTING AT$20', 'STARTING AT$20', 'STARTING AT$40', 'STARTING AT$100', 'STARTING AT$10', 'STARTING AT$10', 'STARTING AT$15', 'STARTING AT$10', 'STARTING AT$10', 'STARTING AT$5', 'STARTING AT$195', 'STARTING AT$10', 'STARTING AT$10', 'STARTING AT$10', 'STARTING AT$15', 'STARTING AT$10', 'STARTING AT$30', 'STARTING AT$150', 'STARTING AT$10', 'STARTING AT$150', 'STARTING AT$20', 'STARTING AT$20', 'STARTING AT$5', 'STARTING AT$10', 'STARTING AT$250', 'STARTING AT$10', 'STARTING AT$5', 'STARTING AT$5', 'STARTING AT$15', 'STARTING AT$50', 'STARTING AT$25', 'STARTING AT$10', 'STARTING AT$30', 'STARTING AT$35', 'STARTING AT$5', 'STARTING AT$5', 'STARTING AT$50', 'STARTING AT$10', 'STARTING AT$5', 'STARTING AT$5', 'STARTING AT$10']\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "price = driver.find_elements(By.CSS_SELECTOR, 'a[class = \"price\"]')\n",
    "print([i.text for i in price])\n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5.0(228)', '5.0(946)', '5.0(637)', '4.9(173)', '5.0(12)', '4.9(243)', '5.0(398)', '5.0(1k+)', '5.0(337)', '5.0(702)', '5.0(30)', '5.0(56)', '4.9(48)', '5.0(26)', '5.0(27)', '5.0(43)', '5.0(266)', '5.0(10)', '5.0(1k+)', '5.0(18)', '', '', '5.0(3)', '', '5.0(8)', '5.0(51)', '5.0(1k+)', '4.8(170)', '5.0(102)', '5.0(162)', '5.0(13)', '', '5.0(181)', '5.0(53)', '5.0(24)', '4.9(347)', '5.0(94)', '5.0(38)', '4.9(423)', '5.0(272)', '5.0(30)', '4.8(277)', '4.9(100)', '5.0(25)', '5.0(4)', '5.0(11)', '5.0(8)', '5.0(188)']\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "c_parent = driver.find_elements(By.CLASS_NAME, 'rating-wrapper')\n",
    "print([i.text for i in c_parent])\n",
    "print(len(c_parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mdyasul', 'ultra_scrape', 'chwasiullah', 'rasedulalif', 'sven_de', 'samsuvo', 'prakriteekhanal', 'adeeltallat', 'jahmadkhan', 'doctorevil92', 'rapidtech1898', 'brilliant_dev', 'ayman_tareq', 'karladaniela715', 'hayat_pashteen', 'kawsar_log', 'asad__haadi', 'excel_hero', 'hotopilams', 'sam_pak', 'bddevelopment23', 'richardbrake', 'smartitguy', 'aussie_prog', 'cadygb', 'ilyasshahid', 'rodazzle', 'robink527', 'scraping_pro', 'pro_marketer_24', 'the_masab', 'redefiningdef', 'adeel085', 'hashamw', 'zeshanali1534', 'nupurds', 'majdmsahel', 'kiritoxy', 'nithinsingh97', 'mr_wajidmaster', 'csgeek', 'faizan1156', 'altaf_ahmed1122', 'jazibhassan', 'hichamalg', 'mramzan0385', 'asharkhursheed', 'robertran63']\n"
     ]
    }
   ],
   "source": [
    "name = driver.find_elements(By.CLASS_NAME, 'seller-name')\n",
    "print([i.text for i in name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Rated Seller\n",
      "Level 2 Seller\n",
      "Top Rated Seller\n",
      "Level 2 Seller\n",
      "No Title\n",
      "Level 2 Seller\n",
      "Top Rated Seller\n",
      "Level 2 Seller\n",
      "Top Rated Seller\n",
      "Top Rated Seller\n",
      "No Title\n",
      "Level 2 Seller\n",
      "Level 2 Seller\n",
      "Level 2 Seller\n",
      "Level 2 Seller\n",
      "Level 2 Seller\n",
      "Level 2 Seller\n",
      "No Title\n",
      "Top Rated Seller\n",
      "Level 1 Seller\n",
      "No Title\n",
      "No Title\n",
      "No Title\n",
      "No Title\n",
      "No Title\n",
      "Level 2 Seller\n",
      "Top Rated Seller\n",
      "Level 2 Seller\n",
      "Level 2 Seller\n",
      "Level 2 Seller\n",
      "Level 1 Seller\n",
      "No Title\n",
      "Level 2 Seller\n",
      "Level 1 Seller\n",
      "Level 1 Seller\n",
      "Top Rated Seller\n",
      "Level 2 Seller\n",
      "Level 2 Seller\n",
      "Level 2 Seller\n",
      "Level 2 Seller\n",
      "Top Rated Seller\n",
      "Level 1 Seller\n",
      "Level 2 Seller\n",
      "No Title\n",
      "No Title\n",
      "No Title\n",
      "No Title\n",
      "Level 2 Seller\n"
     ]
    }
   ],
   "source": [
    "identifier = driver.find_elements(By.CLASS_NAME, 'seller-identifiers')\n",
    "for i in identifier:\n",
    "    try : \n",
    "        level = i.find_element(By.CLASS_NAME, '_5-fo9i5')\n",
    "        print(level.text)\n",
    "    except : \n",
    "        print('No Title')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('scrap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faba58285d1274e92bfe9312e8e316857fb7b69661d7ea0ff2588c6ec1835f06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
